{
  
    
        "post0": {
            "title": "Computers and Networks (Unit 4)",
            "content": "Requirements . Work through College Board Unit 4… blog, add definitions, and pictures. Be creative, for instance make a story of Computing and Networks that is related to your PBL experiences this year. . How a Computer Works . As we have learned, a computer needs a program to do something intelligent. A program sequence executes a series of operations on a computer’s central processing unit (CPU). This component is essentially a binary machine that focuses on the instructions of a given program. The CPU retrieves and stores usable data in random access memory (RAM). Between the processor, RAM, and storage devices, a computer can handle many programs and large amounts of data. . List specification of your Computer, or Computers if working as Pair/Trio . Processor GHz: 1.9 GHz | Memory in GB: 23.9 GB | Storage in GB: 534 GB | OS: Microsoft Windows | . . The Internet . Watch/review College Board Daily Video for 4.1.1 . Essential Knowledge A computing device is a physical artifact that can run a program. Some examples include computers, tablets, servers, routers, and smart sensors. | A computing system is a group of computing devices and programs working together for a common purpose. | A computer network is a group of interconnected computing devices capable of sending or receiving data. | A computer network is a type of computing system. | A path between two computing devices on a computer network (a sender and a receiver) is a sequence of directly connected computing devices that begins at the sender and ends at the receiver. | Routing is the process of finding a path from sender to receiver. | The bandwidth of a computer network is the maximum amount of data that can be sent in a fixed amount of time. | . | Complete Vocabulary Matching Activity. Incorporate this into your learnings from year. To analyze measure path and latency use traceroute and ping commands from Linux Terminal. Path: a: is a sequence of directly connected computing devices that begins at the sender and ends at the receiver | Route: e: is the process of finding a path from sender to receiver | Computer System: b: is a group of computing devices and programs working together for a common purpose. | Computer Device: c: is a physical artifact that can run a program. Some examples include computers, tablets, servers, routers, and smart sensors. | Bandwidth: d: is the maximum amount of data that can be sent in a fixed amount of time | Computer Network: f: is a group of interconnected computing devices capable of sending or receiving data. | . | . Watch/review College Board Daily Video 4.1.2 . Complete True of False Questions | . TRUE: Open standards and protocols enable different manufacturers and developers to build hardware and software that can communicate with hardware and software on the rest of the internet.** | FALSE: IETF is a task force used to enforce laws to keep manufacturers out of the internet.** | FALSE: Routes are determined in advance and are not flexible.** | TRUE: A protocol is an agreed-upon set of rules that specify the behavior of a system.** 5.FALSE: UDP guarantees transfers and is faster.** | FALSE: The World Wide Web is the internet.** | TRUE: HTTP is a protocol used by the World Wide Web.** Essential Knowledge | . The internet is a computer network consisting of interconnected networks that use standardized, open (nonproprierary) communication protocols. | Access to the internet depends on the ability to connect a computing device to an internet connected device. | A protocol is an agreed-upon set of rules that specify the behavior of a system. | The protocols used in the internet are open, which allows users to easily connect additional computing devices to the internet. | Routing on the internet is usually dynamic; it is not specified in advance | The scalability of a system is the capacity for the system to change in size and scale to meet new demands. | The internet was designed to be scalable | Information is passed through the internet as a data stream. Data streams contain chunks of data, which are encapsulated in packets. | Packets contain a chunk of data and metadata used for routing the packet between the origin and the destination on the internet, as well as for data reassembly. | Packets may arrive at the destination in order, out of order, or not at all | IP, TCP and UDP are common protocols used on the internet. | The world wide web is a system of linked pages, programs, and files. | HTTP is a protocol used by the world wide web | The world wide web uses the internet | . | Go over AP videos, vocabulary, and essential knowledge. Draw a diagram showing the internet and its many levels. A preferred diagram would using your knowledge of frontend, backend, deployment, etc. Picture would highligh vocabulary by illustration. The below illustration have some ideas | . . Often we draw pictures of machines communicating over the Internet with arrows. However, the real communication goes through protocol layers and the machine and then is trasported of the network. For College Board and future Computer Knowledge you should become familiar with the following … | . User Machine &lt;&gt; Frontend Server &lt;&gt; Backend Server +--+ +--+ +--+ | Browser | | GH Page | | Flask | +--+ ^ +--+ ^ +--+ | HTTP | | | HTTP | | | HTTP | +--+ | +--+ | +--+ | TCP | | | TCP | | | TCP | +--+ | +--+ | +--+ | IP | V | IP | V | IP | +--+ +--+ +--+ | Network | &lt;&gt; | Network | &lt;&gt; | Network | +--+ +--+ +--+ . The “http” layer is an application layer protocol in the TCP/IP stack, used for communication between web browsers and web servers. It is the protocol used for transmitting data over the World Wide Web. . The “transport” layer (TCP) is responsible for providing reliable data transfer between applications running on different hosts. The TCP protocol segments the data into smaller chunks called “segments”. Each segment contains a sequence number that identifies its position in the original stream of data, as well as other control information such as source and destination port numbers, and checksums for error detection. . The “ip” layer is responsible for packetizing data received from the TCP layer of the protocol stack, and then encapsulating the data into IP packets. The IP packets are then sent to the lower layers of the protocol stack for transmission over the network. . The “network” layer is responsible for routing data packets between networks using the Internet Protocol (IP). This layer handles tasks such as packet addressing and routing, fragmentation and reassembly, and network congestion control. . Fault Tolerance . Watch both Daily videos for 4.2 . Complete the network activity, summarize your understanding of fault tolerance. | . Parallel and Distributed Computing . Review previous lecture on Parallel Computing and watch Daily vidoe 4.3. Think of ways to make something in you team project to utilize Cores more effectively. Here are some thoughts to add to your story of Computers and Networks… . What is naturally Distributed in Frontend/Backend architecture?: AWS can be considered naturally distributed. As a server, it is distributing multiple containers across the architecture to allow for high performance for a large number of instances. This allows for a more efficient backend to frontend connection and a smooth full-stack experience. . | Analyze this command in Docker: ENV GUNICORN_CMD_ARGS=&quot;--workers=1 --bind=0.0.0.0:8086&quot;. Determine if there is options are options in this command for parallel computing within the server that runs python/gunicorn. Here is an article . | . Addition: What it is important about the workers paramater, is that it shows that the amount of in the workers aparamter. It also shows how parallell computing is working out and how that there can be multiple processess the are loading in the app in a parallell function. . Last week we discussed parallel computing on local machine. There are many options. Here is something to get parallel computing work with a tool called Ray. . Review this article… Can you get parallel code on images to work more effectively? I have not tried Ray. | . Addition: The article tht I read made me understand how differnet large objects can make certain objects more useufl in certain applicatiosn through the form of parallel computing. Parallel computing is a type of computation in which many calculations or processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. . Code example from ChatGPT using squares. This might be more interesting if nums we generated to be a lot bigger. | . import ray # define a simple function that takes a number and returns its square def square(x): return x * x # initialize Ray ray.init() # create a remote function that squares a list of numbers in parallel @ray.remote def square_list(nums): return [square(num) for num in nums] # define a list of numbers to square nums = [1, 2, 3, 4, 5] # split the list into two parts split_idx = len(nums) // 2 part1, part2 = nums[:split_idx], nums[split_idx:] # call the remote function in parallel on the two parts part1_result = square_list.remote(part1) part2_result = square_list.remote(part2) # get the results and combine them result = ray.get(part1_result) + ray.get(part2_result) # print the result print(result) .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/18/shivanshcomputernetworks.html",
            "relUrl": "/2023/04/18/shivanshcomputernetworks.html",
            "date": " • Apr 18, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "MCQ Test",
            "content": ". Problem 3 . I chose answer D, An experiment that requires specialized knowledge and training to conduct, but the correct answer was C, An experiment that requires data measurements to be taken in many different locations. What I did wrong was that ciitzen science does not neccessary relate to specializedk nowledge but just to the basic overall of the citizens thorughout the population. . Problem 13 . I chose Answer A, The mobile app release did not have any effect on the average number of daily messages sent per user. But the correct answer was D, The mobile app release led to users tending to write shorter messages. What I did wrong was that I did not read all the different scenarios. . Problem 20 . I chose Answer B, Max, open parenthesis, a comma b, close parenthesis, minus Max, open parenthesis, b comma c, close parenthesis. But the Correct Answer was A Max, open parenthesis, a comma b, close parenthesis, comma, c, close parenthesis. What I Did worng was that I did not accoutn for the variable change . Problem 26 . I chose Answer B, but the correct answer was A because I messed up the order of the Rotate Right and Move Forward. . Problem 31 . I chose Answer A, but the Correct Answer C. The problem was that I focused only on Scenario 1, but I did not focus properly on Secnario 2. . Problem 41 . I chose A, but the correct answer was B. What I Did wrong was that I forgot to incroportate the different FinalExam Weightage at the end. What I can do in the future is to make sure to read the enitre problem and make sure to note down all the differnet variables in the problem. . Problem 47 . I chose B, but the correct answer was D. I got the private key part correct, but I chose the worng perosn. The right answer was to choose the Recipient’s private key and not the sender’s private key. . Problem 55 . I chose the answer C, which is The procedure returns true no matter what the input value is., but the correct answer was DS, The procedure returns false no matter what the input value is. What I did wrong was that I did not read the question correctl and accoutn for the variables. .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/04/18/mcqreview.html",
            "relUrl": "/markdown/week%2020/2023/04/18/mcqreview.html",
            "date": " • Apr 18, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "Duck DNS & AWS Interactive Notebook",
            "content": "Introduction: . Introductory Question . In 2-3 sentences, explain the purpose of DuckDNS as a DNS alternative to what is already in place (Freenom). Do you think we should use one or the other? Why or why not? . Answer: __ . Sample Answer: . DuckDNS provides a free dynamic DNS service that allows users to assign a domain name to a dynamic IP address. It can be used as an alternative to Freenom, which also offers free domain names. The choice between the two depends on individual needs and preferences, such as ease of use, availability of domain extensions, and customer support. . . Setting up DNS . Choose a domain name registrar: . You can select a domain registrar like GoDaddy, Namecheap, or Google Domains to purchase your domain name. . Choose a DNS hosting provider: . You can choose a DNS hosting provider like Cloudflare, Amazon Route 53, or Google Cloud DNS to host your DNS records. . Create DNS records: . After choosing a DNS hosting provider, you need to create DNS records like A records, CNAME records, MX records, and TXT records. . Configure DNS settings: . You can configure DNS settings like TTL (Time To Live), DNSSEC (Domain Name System Security Extensions), and other advanced settings. . from PIL import Image duckdns = Image.open(&quot;../images/duckdns.png&quot;) display(duckdns) . Quiz Time . Now that we have gone over all the neccessary details about what DNS, AWS, and how to set them up using DuckDNS and AWS Servers. Now it is a time for a quiz to test your applications. . import getpass, sys # method to display question and get user&#39;s answers def question_with_response(prompt, qCount): print(&quot;Question &quot; + str(qCount) + &quot; : &quot; + prompt) msg = input() return msg # dictionary to hold questions and answers as key : value pairs questionsDict = {&quot;What does Domain Name Server represent?&quot;: &quot;DNS&quot;, &quot;What does this Represent: Amazon Web Services, which is a cloud computing platform provided by Amazon.&quot;: &quot;AWS&quot;, &quot;What is the first Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;1&quot;, &quot;What is the third Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;3&quot;, &quot;What is the fourth Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;.4&quot;, &quot;What is the second Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;2&quot;, &quot;What files are you supposed to edit after finishing the first steps of setting up the server and cloning it within the AWS Server? 1: Edit the docker files and docker.yml, 2: Edit the main.py file to change the characteristcs.&quot;: &quot;1&quot;, &quot;What is the first step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;1&quot;, &quot;What is the second step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;3&quot;, &quot;What is the third step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;2&quot;, &quot;What is the fourth step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;4&quot; } # number of questions as length of the dictionary questions = len(questionsDict) # set correct to 0 correct = 0 print(&#39;Hello, &#39; + getpass.getuser() + &quot; running &quot; + sys.executable) print(&quot;You will be asked &quot; + str(questions) + &quot; questions.&quot;) print(&quot;Are you ready to take a test! Press Enter key to begin. Best of luck :)&quot;) input() questionCount = 0 # iterate over list of keys from the dictionary. pass dictionary key as question to the question_with_response function for key in questionsDict: questionCount += 1 rsp = question_with_response(key, questionCount) # compare the value from the dictionary to the user&#39;s input if rsp.lower() == questionsDict[key].lower(): print(rsp + &quot; is correct! Good Job!&quot;) correct += 1 else: print(rsp + &quot; is incorrect! Better Luck next time.&quot;) # print final score print(getpass.getuser() + &quot; you scored &quot; + str(correct) +&quot;/&quot; + str(questions)) # calculate percentage page = correct/questions * 100 # print percentage print(&quot;Total Percentage: &quot; + str (format(page,&quot;.2f&quot;)) + &quot;%&quot;) . Hello, shivansh running /home/shivansh/anaconda3/bin/python You will be asked 11 questions. Are you ready to take a test! Press Enter key to begin. Best of luck :) Question 1 : What does Domain Name Server represent? is incorrect! Better Luck next time. Question 2 : What does this Represent: Amazon Web Services, which is a cloud computing platform provided by Amazon. AWS is correct! Good Job! Question 3 : What is the first Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 1 is correct! Good Job! Question 4 : What is the third Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 3 is correct! Good Job! Question 5 : What is the fourth Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 4 is incorrect! Better Luck next time. Question 6 : What is the second Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project is incorrect! Better Luck next time. Question 7 : What files are you supposed to edit after finishing the first steps of setting up the server and cloning it within the AWS Server? 1: Edit the docker files and docker.yml, 2: Edit the main.py file to change the characteristcs. 2 is incorrect! Better Luck next time. Question 8 : What is the first step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 1 is correct! Good Job! Question 9 : What is the second step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 3 is correct! Good Job! Question 10 : What is the third step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 2 is correct! Good Job! Question 11 : What is the fourth step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 4 is correct! Good Job! shivansh you scored 7/11 Total Percentage: 63.64% . FRQ Portion of the Quiz . Complete the answers in the question right below. . Question 1: Why does one using DuckDNS over Freenom? . Question 2: What are all the steps to set up a DuckDNS Severd? . Question 3: What are all the steps to set an AWS SErver? . Conclusion .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/18/duckdnsaws.html",
            "relUrl": "/2023/04/18/duckdnsaws.html",
            "date": " • Apr 18, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "AWS Databases",
            "content": "What are the different types of AWS Databases? . In order to meet the particular requirements of various use cases, AWS provides a variety of database services, each with its own special features and advantages. . Relational databases are among the most widely used AWS database types. Amazon Aurora, Amazon RDS, and Amazon Redshift are just a few of the relational databases that AWS offers. These databases are excellent for structured data and can be applied to financial applications, e-commerce platforms, and content management systems. . Non-relational databases, also known as NoSQL databases, are also provided by AWS. These databases can easily handle high data volumes and were made for unstructured data. Amazon DocumentDB and Amazon DynamoDB are two well-known NoSQL databases that AWS offers. . The graph database is another kind of database that AWS provides. Graph databases are made to store and manage highly connected data, like that found in social networks or recommendation systems. One example of a graph database provided by AWS is Amazon Neptune. . In-memory databases are available through AWS, they offer low-latency speed for applications that require quick data access. Amazon ElastiCache is an example of an in-memory database that can be used for apps like gaming. . In conclusion, the vast variety of databases available by AWS makes it easy for users to use the database that will best fit their work. . Code Example . import boto3 # Create a DynamoDB client dynamodb = boto3.client(&#39;dynamodb&#39;) # Create a table in DynamoDB table_name = &#39;my-table&#39; key_schema = [{&#39;AttributeName&#39;: &#39;id&#39;, &#39;KeyType&#39;: &#39;HASH&#39;}] attribute_definitions = [{&#39;AttributeName&#39;: &#39;id&#39;, &#39;AttributeType&#39;: &#39;S&#39;}] provisioned_throughput = {&#39;ReadCapacityUnits&#39;: 5, &#39;WriteCapacityUnits&#39;: 5} dynamodb.create_table( TableName=table_name, KeySchema=key_schema, AttributeDefinitions=attribute_definitions, ProvisionedThroughput=provisioned_throughput ) # Create an item in DynamoDB item = {&#39;id&#39;: {&#39;S&#39;: &#39;123&#39;}, &#39;name&#39;: {&#39;S&#39;: &#39;John&#39;}} dynamodb.put_item(TableName=table_name, Item=item) # Query items in DynamoDB response = dynamodb.query( TableName=table_name, KeyConditionExpression=&#39;id = :id&#39;, ExpressionAttributeValues={&#39;:id&#39;: {&#39;S&#39;: &#39;123&#39;}} ) items = response[&#39;Items&#39;] # Create an RDS client rds = boto3.client(&#39;rds&#39;) # Create a database instance in RDS db_instance_identifier = &#39;my-instance&#39; db_instance_class = &#39;db.t2.micro&#39; engine = &#39;mysql&#39; master_username = &#39;admin&#39; master_password = &#39;password&#39; allocated_storage = 20 rds.create_db_instance( DBInstanceIdentifier=db_instance_identifier, DBInstanceClass=db_instance_class, Engine=engine, MasterUsername=master_username, MasterUserPassword=master_password, AllocatedStorage=allocated_storage ) # Connect to a database instance in RDS import mysql.connector cnx = mysql.connector.connect( host=&#39;my-instance.cqnkj1234abc.us-east-1.rds.amazonaws.com&#39;, user=&#39;admin&#39;, password=&#39;password&#39;, database=&#39;my-database&#39; ) # Create a table in MySQL cursor = cnx.cursor() create_table_query = ( &quot;CREATE TABLE users (&quot; &quot; id INT NOT NULL AUTO_INCREMENT,&quot; &quot; name VARCHAR(50) NOT NULL,&quot; &quot; PRIMARY KEY (id)&quot; &quot;) ENGINE=InnoDB&quot; ) cursor.execute(create_table_query) # Insert data into a MySQL table insert_query = &quot;INSERT INTO users (name) VALUES (%s)&quot; data = (&#39;John&#39;,) cursor.execute(insert_query, data) cnx.commit() # Query data from a MySQL table select_query = &quot;SELECT * FROM users&quot; cursor.execute(select_query) rows = cursor.fetchall() # Close database connections cursor.close() cnx.close() # test . Quiz . What is the main difference between relational and non-relational databases? . A. Relational databases are only used for structured data, while non-relational databases are only used for unstructured data. . B. Relational databases can easily handle high data volumes, while non-relational databases cannot. . C. Relational databases are based on tables and use SQL, while non-relational databases are based on collections and use JSON-like documents. . D. Relational databases are more expensive than non-relational databases. . Which AWS database service is best suited for applications that require low-latency speed? . A. Amazon ElastiCache . B. Amazon Neptune . C. Amazon DocumentDB . D. Amazon RDS . What is the purpose of the code example provided in the lesson? . A. To demonstrate how to create a table in Amazon Aurora. . B. To show how to query data from a DynamoDB table. . C. To provide an example of how to connect to a database instance in RDS using Python. . D. To showcase how to insert data into a MySQL table. . cac .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/18/DifferentAWS.html",
            "relUrl": "/2023/04/18/DifferentAWS.html",
            "date": " • Apr 18, 2023"
        }
        
    
  
    
        ,"post4": {
            "title": "KASM Virtual Desktop on EC2 Guide",
            "content": "Single Server Installation . We will be going through the single server installation, as this is the most efficient method in terms of ease of deployment. . QUESTION: What are the other installation types? How are they similar or different from the single server installation? . Minimum Requirements . Minimum Requirements . Memory | 4 GB | . CPU | 2 cores | . Storage | 50 GB on SSD | . Installation . Run the following in Terminal to Install: . cd /tmp curl -O https://kasm-static-content.s3.amazonaws.com/kasm_release_1.12.0.d4fd8a.tar.gz # This is downloading the latest version of KASM workspaces to the /tmp folder. tar -xf kasm_release_1.12.0.d4fd8a.tar.gz # This is extracting the package which was just downloaded. sudo bash kasm_release/install.sh # The installation script is being run for KASM. . Swap Partition . As recommended by KASM, a swap partition should be created for a smooth experience. Without a swap partition, a host with memory requirements being sufficiently met can meet stability problems. . If your PC does not have a swap file, you will need to create one immediately after installing KASM. . Run the following command in Terminal: . sudo bash kasm_release/install.sh --accept-eula --swap-size 4096 . Login Information . After the package for the latest version of KASM has been extracted to the right folder and a swap partition has been created, you can log into the web application. The web application runs on port 443 (though configurations can be altered to run on another port): . https://WEBAPP_SERVER_NAME_HERE . You want to login with the Administrator account, which is defaulted to admin@kasm.local with randomly generated passwords. This will allow you to manage environments and workspaces. . KASM Configurations . Once you are logged in, you can change KASM configuration settings as an administrator by navigating to the &quot;Settings&quot; tab on the left side. . Here are all of the settings stored in server settings which you can research in your free time: https://kasmweb.com/docs/latest/guide/settings.html . Here, there are hundreds of settings which you can take a look at. Depending on the setting you are changing, you may need to restart ALL KASM services or certain individual services. . Take a look below for the commands for these service restarts: . cd /opt/kasm/bin # The opt directory is for all software and packages that are not installed by default on Linux. # This makes sense, since we installed KASM separately. ./stop ./start # All the services have been restarted. # Restarting individual services on the server: sudo docker restart kasm_agent sudo docker restart kasm_api sudo docker restart kasm_manager sudo docker restart kasm_db sudo docker restart kasm_proxy . IMPORTANT . You should be able to run all of this in an ec2 instance on AWS and then be able to run docker images stored on your instance through KASM. However, storage on EC2 instances is limited. If you are able to run docker images on an ec2 instance with KASM, that would be really impressive. . HACKS FOR KASM . In 3-4 sentences, please explain the significance of virtual desktops and KASM. How can virtual desktops such as these be utilized in our AP CSP environment? (0.45) . | Attempt to work through the KASM setup with your team. Attach two screenshots to show that you have successfully gone through the setup: The first screenshot of KASM generating your credentials, and the second screenshot of the KASM workspace once you have logged in. (0.45) . |",
            "url": "https://tri3devopteam.github.io/devops/2023/04/13/kasmec2.html",
            "relUrl": "/2023/04/13/kasmec2.html",
            "date": " • Apr 13, 2023"
        }
        
    
  
    
        ,"post5": {
            "title": "MCQ Test",
            "content": ". Problem 23 . What I did wrong was that I chose answer D, “An online retailer analyzing customers’ viewing habits to suggest other products based on the purchasing history of other customers”, but the answer was actually C, “A high school analyzing student grades to identify the students with the top ten highest grade point averages”. . Problem 44 . I chose answer B, “The student is modifying the search procedure to take a definition as an argument and return the corresponding word.”, but the answer was C, “The student is reusing the computer scientist’s procedural abstraction by knowing what the procedure does without knowing how it does it.” . Problem 49 . I chose answer C, but the correct answer was A. What I did wrong was that I did not read the code correctly which led to me getting the answer done. .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/04/03/mcqtest.html",
            "relUrl": "/markdown/week%2020/2023/04/03/mcqtest.html",
            "date": " • Apr 3, 2023"
        }
        
    
  
    
        ,"post6": {
            "title": "Title",
            "content": "acme.sh: acme.sh is a shell script that provides an alternative way to obtain and manage SSL/TLS certificates. It is a lightweight and versatile tool that can be used on a wide variety of web servers, including Apache, Nginx, and HAProxy. acme.sh uses the ACME protocol to communicate with Let&#39;s Encrypt and other certificate authorities, and supports a variety of verification methods, including DNS, HTTP, and TLS-SNI. Here&#39;s an example Python code that uses acme.sh to obtain a certificate for a domain: . import subprocess # set the domain name and web root directory domain = &quot;example.com&quot; webroot = &quot;/var/www/html&quot; # run the acme.sh command to obtain a certificate cmd = f&quot;acme.sh --issue --webroot {webroot} -d {domain}&quot; subprocess.run(cmd.split()) . ZeroSSL: ZeroSSL is a web-based certificate management tool that provides an alternative to Certbot. It allows you to obtain and manage SSL/TLS certificates through a web interface, without the need to install any software on your server. ZeroSSL supports both Let&#39;s Encrypt and Sectigo certificate authorities, and offers a variety of verification methods, including HTTP, DNS, and Email. Here&#39;s an example Python code that uses ZeroSSL to obtain a certificate for a domain: . import requests # set the domain name and email address domain = &quot;example.com&quot; email = &quot;user@example.com&quot; # make a request to ZeroSSL to obtain a certificate response = requests.post(&quot;https://zerossl.com/api/v2/certificates&quot;, json={ &quot;email&quot;: email, &quot;domains&quot;: [domain], &quot;certificate_validity_days&quot;: 90, &quot;validation_methods&quot;: [&quot;http&quot;, &quot;https&quot;, &quot;dns&quot;] }) # get the certificate data from the response certificate = response.json()[&quot;certificate&quot;] private_key = response.json()[&quot;key&quot;] . ego: lego is a command-line tool that provides an alternative to Certbot for managing SSL/TLS certificates. It supports a variety of web servers, including Apache, Nginx, and Caddy, and uses the ACME protocol to communicate with Let&#39;s Encrypt and other certificate authorities. lego offers a wide range of features, including support for wildcard certificates, DNS validation, and certificate bundling. Here&#39;s an example Python code that uses lego to obtain a certificate for a domain: .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/03/Certbot.html",
            "relUrl": "/2023/04/03/Certbot.html",
            "date": " • Apr 3, 2023"
        }
        
    
  
    
        ,"post7": {
            "title": "Guide to SQLite vs AWS alternate databases",
            "content": "What is AWS . AWS offers several alternate databases in addition to their popular managed relational database service (RDS). These alternate databases provide different functionality and are optimized for specific use cases. One such alternate database is Amazon DynamoDB, which is a fast and flexible NoSQL database service that allows users to store and retrieve any amount of data, with low latency and predictable performance.Another alternate database offered by AWS is Amazon Neptune, which is a fast, reliable, and fully-managed graph database service that makes it easy to build and run applications that work with highly connected datasets. . What is SQlite . SQLite is a widely used embedded database management system that is known for its simplicity, reliability, and ease of use. It is a serverless, self-contained, and transactional database engine that is designed to be embedded into applications rather than run as a standalone server. SQLite databases are stored as files on disk, making them easy to backup, copy, and transport between systems. They support standard SQL syntax and are fully ACID compliant, ensuring data consistency and reliability. . import sqlite3 conn = sqlite3.connect(&#39;example.db&#39;) c = conn.cursor() # create table c.execute(&#39;&#39;&#39;CREATE TABLE stocks (date text, symbol text, price real)&#39;&#39;&#39;) # insert data c.execute(&quot;INSERT INTO stocks VALUES (&#39;2022-03-27&#39;, &#39;AAPL&#39;, 133.52)&quot;) # save changes conn.commit() # query data for row in c.execute(&#39;SELECT * FROM stocks&#39;): print(row) conn.close() . AWS Vs SQlite . SQLite is a lightweight, file-based relational database management system (RDBMS) that is well-suited for small-scale projects or applications. AWS offers a wide range of database options, including relational, NoSQL, and in-memory databases, each with its own set of pros and cons. Here are some of the pros and cons of alternative AWS databases in comparison to SQLite: . Amazon Relational Database Service (RDS): Amazon RDS is a fully managed relational database service that supports multiple database engines, including MySQL, PostgreSQL, and Oracle. Pros: . Scalability: RDS can easily scale to handle a large amount of traffic and data. High Availability: RDS offers automatic failover and backup options to ensure data availability. Security: RDS offers robust security features, such as encryption at rest and in transit. Managed Service: RDS is a managed service, meaning that AWS handles the administrative tasks of the database, such as backups, updates, and maintenance. Cons: . Cost: RDS can be more expensive than SQLite, especially for small-scale projects or applications. Complexity: RDS can be more complex to set up and manage than SQLite. Amazon DynamoDB: Amazon DynamoDB is a NoSQL database that can handle large amounts of data and is designed for scalability and high availability. . AWS Databases . Amazon Web Services (AWS) provides a range of database services to meet various data storage and processing needs. Some of the popular AWS databases are: . Amazon Relational Database Service (RDS): It provides fully managed relational databases, such as MySQL, PostgreSQL, Oracle, SQL Server, and Amazon Aurora. . Amazon DynamoDB: It is a fully managed NoSQL database service that provides high performance, scalability, and automatic scaling of throughput capacity. . Amazon Neptune: It is a fully managed graph database service that enables you to store and query highly connected data sets. . Amazon DocumentDB: It is a fully managed document database service that is compatible with MongoDB workloads . Code example: Source Geeks4Geeks.com . import boto3 # create an RDS client rds = boto3.client(&#39;rds&#39;) # create a database instance db_instance_identifier = &#39;mydbinstance&#39; db_instance_class = &#39;db.t2.micro&#39; engine = &#39;mysql&#39; master_username = &#39;myusername&#39; master_password = &#39;mypassword&#39; allocated_storage = 20 rds.create_db_instance( DBInstanceIdentifier=db_instance_identifier, DBInstanceClass=db_instance_class, Engine=engine, MasterUsername=master_username, MasterUserPassword=master_password, AllocatedStorage=allocated_storage ) # wait for the instance to become available rds.get_waiter(&#39;db_instance_available&#39;).wait( DBInstanceIdentifier=db_instance_identifier ) # create a database connection import mysql.connector cnx = mysql.connector.connect( host=&#39;mydbinstance.cquf123456.us-west-2.rds.amazonaws.com&#39;, user=&#39;myusername&#39;, password=&#39;mypassword&#39;, database=&#39;mydatabase&#39; ) # create a table cursor = cnx.cursor() table_query = ( &quot;CREATE TABLE IF NOT EXISTS users (&quot; &quot; id INT AUTO_INCREMENT PRIMARY KEY,&quot; &quot; name VARCHAR(255),&quot; &quot; email VARCHAR(255)&quot; &quot;)&quot; ) cursor.execute(table_query) # insert data insert_query = &quot;INSERT INTO users (name, email) VALUES (%s, %s)&quot; data = (&#39;John&#39;, &#39;john@example.com&#39;) cursor.execute(insert_query, data) # query data select_query = &quot;SELECT * FROM users&quot; cursor.execute(select_query) for row in cursor: print(row) # close the cursor and connection cursor.close() cnx.close() # delete the database instance rds.delete_db_instance( DBInstanceIdentifier=db_instance_identifier, SkipFinalSnapshot=True ) # wait for the instance to be deleted rds.get_waiter(&#39;db_instance_deleted&#39;).wait( DBInstanceIdentifier=db_instance_identifier ) . Which of the following is not an AWS database option? . A. Amazon RDS . B. Amazon Neptune . C. SQLite . D. Amazon DynamoDB . Which of the following is a file-based, lightweight RDBMS? . A. Amazon RDS . B. Amazon Neptune . C Amazon DynamoDB . D. SQLite . Which AWS service enables you to store and query highly connected datasets? . A. Amazon Relational Database Service (RDS) . B. Amazon DynamoDB . C. Amazon Neptune . D. Amazon DocumentDB . cdc .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/02/AWSSQL.html",
            "relUrl": "/2023/04/02/AWSSQL.html",
            "date": " • Apr 2, 2023"
        }
        
    
  
    
        ,"post8": {
            "title": "AWS Databases",
            "content": "What are the different types of AWS Databases? . In order to meet the particular requirements of various use cases, AWS provides a variety of database services, each with its own special features and advantages. . Relational databases are among the most widely used AWS database types. Amazon Aurora, Amazon RDS, and Amazon Redshift are just a few of the relational databases that AWS offers. These databases are excellent for structured data and can be applied to financial applications, e-commerce platforms, and content management systems. . Non-relational databases, also known as NoSQL databases, are also provided by AWS. These databases can easily handle high data volumes and were made for unstructured data. Amazon DocumentDB and Amazon DynamoDB are two well-known NoSQL databases that AWS offers. . The graph database is another kind of database that AWS provides. Graph databases are made to store and manage highly connected data, like that found in social networks or recommendation systems. One example of a graph database provided by AWS is Amazon Neptune. . In-memory databases are available through AWS, they offer low-latency speed for applications that require quick data access. Amazon ElastiCache is an example of an in-memory database that can be used for apps like gaming. . In conclusion, the vast variety of databases available by AWS makes it easy for users to use the database that will best fit their work. .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2028/2023/03/28/redobigidea2-copy.html",
            "relUrl": "/markdown/week%2028/2023/03/28/redobigidea2-copy.html",
            "date": " • Mar 28, 2023"
        }
        
    
  
    
        ,"post9": {
            "title": "Duck DNS (Shaurya Goel)",
            "content": "How does Duck DNS Work? . Duck DNS is a free dynamic DNS service that allows users to assign a domain name to a dynamic IP address. Dynamic DNS (DDNS) is a system used to map a domain name to an IP address that may change frequently, such as the IP address assigned by an ISP to a residential or small business internet connection. . Once the client program is set up, it will periodically send an update to the Duck DNS servers with your current IP address. When someone tries to access your domain name, the DNS server will resolve the domain name to your current IP address, allowing the requester to connect to your device. . Overall, Duck DNS provides a convenient way to access your home network or devices from anywhere in the world, even if your ISP assigns you a dynamic IP address . How is Duck DNS useful for our project? Other Projects in General? . In general, Duck DNS can be useful for projects that involve remote access or control of a device, such as setting up a home security camera, remote desktop access, or hosting a website or game server from a home network. By using Duck DNS, the device or service can be accessed using a static hostname, which is more convenient than having to remember or constantly look up the device’s changing IP address. . In addition, Duck DNS is easy to set up and does not require any special hardware or software. It can be configured to update the IP address automatically, making it a reliable and low-maintenance solution for dynamic IP addresses. . Overall, Duck DNS is a useful tool for any project that requires a static hostname for remote access or control of a device or service. . Steps for Setup . Sign up for a DuckDNS account by visiting https://www.duckdns.org/ and selecting “Create Account.” | Once you have created an account, you will be prompted to create a subdomain. Enter a unique name for your subdomain, and then click the “Add Domain” button. | Next, you will need to download the DuckDNS client to keep your IP address updated. You can find the client at https://www.duckdns.org/install.jsp. Choose the appropriate client for your operating system. | Once you have downloaded the client, extract the files and run the installation script. | After installation, you will be prompted to enter your DuckDNS subdomain and token. You can find your token by logging into your DuckDNS account and clicking the “Install” tab. | Start the DuckDNS client, and it will automatically update your IP address every time it changes. You can confirm that the client is working by checking the “Logs” tab in your DuckDNS account. | Finally, you can use your DuckDNS subdomain to access your home network from the internet. To do this, you will need to configure your router to forward incoming requests to your local IP address. | . Video . Kahoot .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/03/27/DuckDNS.html",
            "relUrl": "/markdown/week%2020/2023/03/27/DuckDNS.html",
            "date": " • Mar 27, 2023"
        }
        
    
  
    
        ,"post10": {
            "title": "AWS Devolpment",
            "content": "by: Shivansh Goel . AWS Devolpment . Basic Terms . EC2: Amazon Web Services is a cloud computing platform that the PUSD district has provided for their students to serve our Web Application. | GitHub: The leading open platform to share a code across the Internet. Docker and docker-compose: Used to host a Web Application. A Docker container prepares an environment that contains the Web Application code and all the dependencies (requirements.txt for Python) Docker is an open platform for developing, shipping, and running applications. | Nginx: In order to find a Web Application on a server, there needs to be a process that listens for the Web Application request and directs it to the Web Application service. Nginx is an open source software for web serving, reverse proxy, caching, load balancing, media streaming, and more. | Certbot: Web traffic on internet is reliably served over Secure Hyper Text Transfer Protocol (https). Certbot is a free, open source software tool for automatically using Let’s Encrypt certifications. | DNS: Natively, the web works off of IP addresses. Domain Name Services (DNS) allows the assignment of a friendly name to a Web Server. This name is built into Nginx/Certbot configuration files. Freenom is the cloud service described in this blog and has been used to register the nighthawkcodingsociety.com domain | . Setting up the Server and Cloning the Project . First connect to an Ubuntu EC2 instance on AWS and then begin the system and software setup. | Once you get in the server, then you must start the upgrade, update, and delete process. Some commands include: sudo apt-get update, sudo apt-get upgrade | Clone and Change Directory to project location. After all the update and upgrade commands are completed then clone the project in a single directory and change the directory to which the place is located | After the flask server has been put in the server then check if it can run through various commands: python main.py After running the command: “python main.py” It should say muliple stuff like “Debbuger Pin Activated” and a Link will show up | . Create Dockerfile to run Web Service . Edit the DockerFIle and add “CMD [ “gunicorn”, “main:app” ]” at the end of the code | Edit the dcoker-compose.yml file and edit the flask_port and docker file location | . Testing Localpoint . To make sure that all the previous steps are running correctly and the everything is going on the right path. You should run these commands to see if there is a success or a failure. . curl http://localhost:8086 If there is a “Failed to connect”, then that means that something is not going right and that you should look at the changes you have made in the server. | Another command to run would be: curl http://localhost:8086 | html2text | . | . Test preparation for Docker Web Application using IP for Internet Access . Prerequisites: Installing Nginx . Run the command to make sure that Nginx is installed within the system: sudo apt install nginx Move to /etc/nginx/sites-available whichis where the Nginx Server Configuration Files are located | Create your own file in the thing | . Are there any outdated Nginx/Docker functionalities to address? . As of right now there are no outdate Nginx/Docker functionalities that needed to be adressed, except to make sure to periodically run “sudo apt-get update”, and “‘sudo apt-get upgrade” | . Is there anything unclear that we need to communicate further to the students for deployment? . There is nothing unclear that needs to be communicated further except for the usage of the DuckDNS for the DNS Account and Server .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/03/27/AWSDevolpment.html",
            "relUrl": "/markdown/week%2020/2023/03/27/AWSDevolpment.html",
            "date": " • Mar 27, 2023"
        }
        
    
  
    
        ,"post11": {
            "title": "KASM Intro Guide",
            "content": "What is KASM? . In the words of the KASM co-director: . “KASM Workspaces delivers interactive access to GUI applications and desktop environments running in docker containers. The containers are streamed directly to the browser. The platform is similar to Citrix and VMware Horizon, but entirely container based.” . Essentially, KASM allows you to stream applications from docker containers. . Functionality Link: . KASM Functionalities . There are many different types of workspaces that KASM offers, such as: . Desktop Workspaces: Here, you can get desktop access in a moment of seconds from any device and from anywhere around the world. It is done in a secure manner through whichever web browser you like. | Functionality Demo: . Web Isolation Workspaces: There is a “zero-trust browser isolation” service. You can launch a private web browsing instance, where there is “no risk of compromising your endpoint.” | Functionality Demo: . Application Workspace (App Streaming): This is the main workspace which we are going to focus on. This workspace allows for an application container where the KASM platform does most of the heavylifting for us. It is customizable, open source, and kept up to date. You can choose either a server or cloud deployment option, and you can manage your own Self-Hosted Server in a separate version type created for this situation. | There are three different option plans for KASM: . Community Plan: Offers all enterprise features, and it is for personal use. You get community support, but there is a 5 concurrent session limit. . | Professional Plan: This is a $5 user/month plan. You get next business day support with this plan and a higher session limit. . | Their recommended plan, the Enterprise Plan: This is a $10 user/month plan, where you can get same business day support with all of the supported professional plan features. . | Why KASM? . It is incredibly scalable, and deployment automation can be done “for unique requirements and at massive scale” . | Easy to Access: You can log in from any web browser and whatever you are deploying can be hosted anywhere: private cloud, KASM hosted, etc. . | High Efficiency Levels: Uses Docker containers, reducing the resource requirements and creating fast session boots . | Very well-managed security: 2FA, LDAP, data loss prevention, security groups for privilege control of deployment, logging, and web filtering. . | Open-Source: All container tech available on Docker Hub and GitHub for people to view . |",
            "url": "https://tri3devopteam.github.io/devops/markdown/2023/03/26/kasm.html",
            "relUrl": "/markdown/2023/03/26/kasm.html",
            "date": " • Mar 26, 2023"
        }
        
    
  
    
        ,"post12": {
            "title": "Advanced Security Certbot",
            "content": "Certbot is a software run in Python. It is meant to convert HTTP sites to work with HTTPS, which is much more secure. Let’s first explore the background of HTTP to HTTPS: HTTPS and HTTP are almost essentially the same protocols, but HTTPS uses SSL to encrypt the requests and responses. Furthermore, HTTPS is also used in the form of SSL certificates used to encrypt and digitally sign these requests. HTTP runs on port 80, and is an incredibly insecure platform to run a site on. HTTPS runs on ports 80 and 443, and needs a Certification Authority signature for the SSL certificate being used on the https site. APPLICATION IN CSP, PROS/CONS During Trimester 1, while initially setting up our AWS deployment, we attempted to implement Let’s Encrypt, a certificate authority manager, along with Certbot. The Certbot configuration is relatively easy: as shown in Trimester 1, you have to install a couple of packages, create the certbot folders on the AWS deployment server, and activate HTTPS for your domain. Though it is relatively easy to use, we decided to weigh out some of the pros/cons of using Let’s Encrypt &amp; Certbot: PROS: . Let’s Encrypt is a free service. | It is issued very efficiently. | It is something that most of our students are already familiar with, so it is a smoother process to setup. CONS: | Certificates have to be replaced/renewed every 90 days. This can be a painful process, especially for multiple sites and groups to do. | Some domains block Let’s Encrypt, and have relationships with other SSL providers. | It is a platform that is vulnerable to malware attacks. Almost 15 thousand Let’s Encrypt certificates have been issued to phishing sites. Is this another risk that we want to factor in? In our opinion, this is too much to consider and it could be beneficial to look at alternatives. | To install and setup Certbot follow these instructions: . Install Certbot through the terminal with the following command sudo apt-get install certbot . | Next we have to choose a plugin to obtain and install the certificates. For Apache web servers, you can use the following command. If you are using a different browser engine, you can choose the corresponding plugin for that browser engine. sudo certbot –apache . | Next, you will need to follow the given prompts and certbot will help us set the rest up. You will need to enter your email address. . | Now you have to verify the installation and you can check if it’s working by checking the website in your browser, or using a tool such as SSL Labs, which can check for an SSL certificate. . | Now you have to ensure that your certbot will continue working with minimum maintenance. You can do this by making the certificate auto renew using this command. sudo certbot renew . |",
            "url": "https://tri3devopteam.github.io/devops/markdown/2023/03/26/certbot.html",
            "relUrl": "/markdown/2023/03/26/certbot.html",
            "date": " • Mar 26, 2023"
        }
        
    
  

  
  
      ,"page0": {
          "title": "",
          "content": "Blogs .",
          "url": "https://tri3devopteam.github.io/devops/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tri3devopteam.github.io/devops/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}