{
  
    
        "post0": {
            "title": "AWS Databases",
            "content": "What are the different types of AWS Databases? . In order to meet the particular requirements of various use cases, AWS provides a variety of database services, each with its own special features and advantages. . Relational databases are among the most widely used AWS database types. Amazon Aurora, Amazon RDS, and Amazon Redshift are just a few of the relational databases that AWS offers. These databases are excellent for structured data and can be applied to financial applications, e-commerce platforms, and content management systems. . Non-relational databases, also known as NoSQL databases, are also provided by AWS. These databases can easily handle high data volumes and were made for unstructured data. Amazon DocumentDB and Amazon DynamoDB are two well-known NoSQL databases that AWS offers. . The graph database is another kind of database that AWS provides. Graph databases are made to store and manage highly connected data, like that found in social networks or recommendation systems. One example of a graph database provided by AWS is Amazon Neptune. . In-memory databases are available through AWS, they offer low-latency speed for applications that require quick data access. Amazon ElastiCache is an example of an in-memory database that can be used for apps like gaming. . Code Example . import boto3 # Create a DynamoDB client dynamodb = boto3.client(&#39;dynamodb&#39;) # Create a table in DynamoDB table_name = &#39;my-table&#39; key_schema = [{&#39;AttributeName&#39;: &#39;id&#39;, &#39;KeyType&#39;: &#39;HASH&#39;}] attribute_definitions = [{&#39;AttributeName&#39;: &#39;id&#39;, &#39;AttributeType&#39;: &#39;S&#39;}] provisioned_throughput = {&#39;ReadCapacityUnits&#39;: 5, &#39;WriteCapacityUnits&#39;: 5} dynamodb.create_table( TableName=table_name, KeySchema=key_schema, AttributeDefinitions=attribute_definitions, ProvisionedThroughput=provisioned_throughput ) # Create an item in DynamoDB item = {&#39;id&#39;: {&#39;S&#39;: &#39;123&#39;}, &#39;name&#39;: {&#39;S&#39;: &#39;John&#39;}} dynamodb.put_item(TableName=table_name, Item=item) # Query items in DynamoDB response = dynamodb.query( TableName=table_name, KeyConditionExpression=&#39;id = :id&#39;, ExpressionAttributeValues={&#39;:id&#39;: {&#39;S&#39;: &#39;123&#39;}} ) items = response[&#39;Items&#39;] # Create an RDS client rds = boto3.client(&#39;rds&#39;) # Create a database instance in RDS db_instance_identifier = &#39;my-instance&#39; db_instance_class = &#39;db.t2.micro&#39; engine = &#39;mysql&#39; master_username = &#39;admin&#39; master_password = &#39;password&#39; allocated_storage = 20 rds.create_db_instance( DBInstanceIdentifier=db_instance_identifier, DBInstanceClass=db_instance_class, Engine=engine, MasterUsername=master_username, MasterUserPassword=master_password, AllocatedStorage=allocated_storage ) # Connect to a database instance in RDS import mysql.connector cnx = mysql.connector.connect( host=&#39;my-instance.cqnkj1234abc.us-east-1.rds.amazonaws.com&#39;, user=&#39;admin&#39;, password=&#39;password&#39;, database=&#39;my-database&#39; ) # Create a table in MySQL cursor = cnx.cursor() create_table_query = ( &quot;CREATE TABLE users (&quot; &quot; id INT NOT NULL AUTO_INCREMENT,&quot; &quot; name VARCHAR(50) NOT NULL,&quot; &quot; PRIMARY KEY (id)&quot; &quot;) ENGINE=InnoDB&quot; ) cursor.execute(create_table_query) # Insert data into a MySQL table insert_query = &quot;INSERT INTO users (name) VALUES (%s)&quot; data = (&#39;John&#39;,) cursor.execute(insert_query, data) cnx.commit() # Query data from a MySQL table select_query = &quot;SELECT * FROM users&quot; cursor.execute(select_query) rows = cursor.fetchall() # Close database connections cursor.close() cnx.close() # test . Quiz . What is the main difference between relational and non-relational databases? . A. Relational databases are only used for structured data, while non-relational databases are only used for unstructured data. . B. Relational databases can easily handle high data volumes, while non-relational databases cannot. . C. Relational databases are based on tables and use SQL, while non-relational databases are based on collections and use JSON-like documents. . D. Relational databases are more expensive than non-relational databases. . Which AWS database service is best suited for applications that require low-latency speed? . A. Amazon ElastiCache . B. Amazon Neptune . C. Amazon DocumentDB . D. Amazon RDS . What is the purpose of the code example provided in the lesson? . A. To demonstrate how to create a table in Amazon Aurora. . B. To show how to query data from a DynamoDB table. . C. To provide an example of how to connect to a database instance in RDS using Python. . D. To showcase how to insert data into a MySQL table. . cac .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/23/DifferentAWS.html",
            "relUrl": "/2023/04/23/DifferentAWS.html",
            "date": " • Apr 23, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Duck DNS & AWS Interactive Notebook",
            "content": "Introduction: . Introductory Question . In 2-3 sentences, explain the purpose of DuckDNS as a DNS alternative to what is already in place (Freenom). Do you think we should use one or the other? Why or why not? . Answer: __ . Sample Answer: . DuckDNS provides a free dynamic DNS service that allows users to assign a domain name to a dynamic IP address. It can be used as an alternative to Freenom, which also offers free domain names. The choice between the two depends on individual needs and preferences, such as ease of use, availability of domain extensions, and customer support. . . Setting up DNS . Choose a domain name registrar: . You can select a domain registrar like GoDaddy, Namecheap, or Google Domains to purchase your domain name. . Choose a DNS hosting provider: . You can choose a DNS hosting provider like Cloudflare, Amazon Route 53, or Google Cloud DNS to host your DNS records. . Create DNS records: . After choosing a DNS hosting provider, you need to create DNS records like A records, CNAME records, MX records, and TXT records. . Configure DNS settings: . You can configure DNS settings like TTL (Time To Live), DNSSEC (Domain Name System Security Extensions), and other advanced settings. . from PIL import Image duckdns = Image.open(&quot;../images/duckdns.png&quot;) display(duckdns) . Quiz Time . Now that we have gone over all the neccessary details about what DNS, AWS, and how to set them up using DuckDNS and AWS Servers. Now it is a time for a quiz to test your applications. . import getpass, sys # method to display question and get user&#39;s answers def question_with_response(prompt, qCount): print(&quot;Question &quot; + str(qCount) + &quot; : &quot; + prompt) msg = input() return msg # dictionary to hold questions and answers as key : value pairs questionsDict = {&quot;What does Domain Name Server represent?&quot;: &quot;DNS&quot;, &quot;What does this Represent: Amazon Web Services, which is a cloud computing platform provided by Amazon.&quot;: &quot;AWS&quot;, &quot;What is the first Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;1&quot;, &quot;What is the third Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;3&quot;, &quot;What is the fourth Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;.4&quot;, &quot;What is the second Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project&quot;: &quot;2&quot;, &quot;What files are you supposed to edit after finishing the first steps of setting up the server and cloning it within the AWS Server? 1: Edit the docker files and docker.yml, 2: Edit the main.py file to change the characteristcs.&quot;: &quot;1&quot;, &quot;What is the first step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;1&quot;, &quot;What is the second step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;3&quot;, &quot;What is the third step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;2&quot;, &quot;What is the fourth step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script&quot;: &quot;4&quot; } # number of questions as length of the dictionary questions = len(questionsDict) # set correct to 0 correct = 0 print(&#39;Hello, &#39; + getpass.getuser() + &quot; running &quot; + sys.executable) print(&quot;You will be asked &quot; + str(questions) + &quot; questions.&quot;) print(&quot;Are you ready to take a test! Press Enter key to begin. Best of luck :)&quot;) input() questionCount = 0 # iterate over list of keys from the dictionary. pass dictionary key as question to the question_with_response function for key in questionsDict: questionCount += 1 rsp = question_with_response(key, questionCount) # compare the value from the dictionary to the user&#39;s input if rsp.lower() == questionsDict[key].lower(): print(rsp + &quot; is correct! Good Job!&quot;) correct += 1 else: print(rsp + &quot; is incorrect! Better Luck next time.&quot;) # print final score print(getpass.getuser() + &quot; you scored &quot; + str(correct) +&quot;/&quot; + str(questions)) # calculate percentage page = correct/questions * 100 # print percentage print(&quot;Total Percentage: &quot; + str (format(page,&quot;.2f&quot;)) + &quot;%&quot;) . Hello, shivansh running /home/shivansh/anaconda3/bin/python You will be asked 11 questions. Are you ready to take a test! Press Enter key to begin. Best of luck :) Question 1 : What does Domain Name Server represent? is incorrect! Better Luck next time. Question 2 : What does this Represent: Amazon Web Services, which is a cloud computing platform provided by Amazon. AWS is correct! Good Job! Question 3 : What is the first Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 1 is correct! Good Job! Question 4 : What is the third Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 3 is correct! Good Job! Question 5 : What is the fourth Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project 4 is incorrect! Better Luck next time. Question 6 : What is the second Step to setting up an AWS Server? 1: Connecting to a Ubuntu EC2 Instance, 2: Start updating the system, 3: Clone the repository which one wishes to deploy, 4: Run the command: main.py to start the project is incorrect! Better Luck next time. Question 7 : What files are you supposed to edit after finishing the first steps of setting up the server and cloning it within the AWS Server? 1: Edit the docker files and docker.yml, 2: Edit the main.py file to change the characteristcs. 2 is incorrect! Better Luck next time. Question 8 : What is the first step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 1 is correct! Good Job! Question 9 : What is the second step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 3 is correct! Good Job! Question 10 : What is the third step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 2 is correct! Good Job! Question 11 : What is the fourth step to setting up a DuckDNS Server? 1: Signing up for a DuckDNS account, 2: Download the DuckDNS client , 3: Create the subdomain, 4: Run the installation script 4 is correct! Good Job! shivansh you scored 7/11 Total Percentage: 63.64% . FRQ Portion of the Quiz . Complete the answers in the question right below. . Question 1: Why does one using DuckDNS over Freenom? . Question 2: What are all the steps to set up a DuckDNS Sever? . Question 3: What are all the steps to set an AWS Server? . Reflection? . Can you now deploy on AWS with a DNS Server .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/18/duckdnsaws.html",
            "relUrl": "/2023/04/18/duckdnsaws.html",
            "date": " • Apr 18, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "KASM Virtual Desktop on EC2 Guide",
            "content": "Single Server Installation . We will be going through the single server installation, as this is the most efficient method in terms of ease of deployment. . QUESTION: What are the other installation types? How are they similar or different from the single server installation? . Minimum Requirements . Minimum Requirements . Memory | 4 GB | . CPU | 2 cores | . Storage | 50 GB on SSD | . Installation . Run the following in Terminal to Install: . cd /tmp curl -O https://kasm-static-content.s3.amazonaws.com/kasm_release_1.12.0.d4fd8a.tar.gz # This is downloading the latest version of KASM workspaces to the /tmp folder. tar -xf kasm_release_1.12.0.d4fd8a.tar.gz # This is extracting the package which was just downloaded. sudo bash kasm_release/install.sh # The installation script is being run for KASM. . Swap Partition . As recommended by KASM, a swap partition should be created for a smooth experience. Without a swap partition, a host with memory requirements being sufficiently met can meet stability problems. . If your PC does not have a swap file, you will need to create one immediately after installing KASM. . Run the following command in Terminal: . sudo bash kasm_release/install.sh --accept-eula --swap-size 4096 . Login Information . After the package for the latest version of KASM has been extracted to the right folder and a swap partition has been created, you can log into the web application. The web application runs on port 443 (though configurations can be altered to run on another port): . https://WEBAPP_SERVER_NAME_HERE . You want to login with the Administrator account, which is defaulted to admin@kasm.local with randomly generated passwords. This will allow you to manage environments and workspaces. . KASM Configurations . Once you are logged in, you can change KASM configuration settings as an administrator by navigating to the &quot;Settings&quot; tab on the left side. . Here are all of the settings stored in server settings which you can research in your free time: https://kasmweb.com/docs/latest/guide/settings.html . Here, there are hundreds of settings which you can take a look at. Depending on the setting you are changing, you may need to restart ALL KASM services or certain individual services. . Take a look below for the commands for these service restarts: . cd /opt/kasm/bin # The opt directory is for all software and packages that are not installed by default on Linux. # This makes sense, since we installed KASM separately. ./stop ./start # All the services have been restarted. # Restarting individual services on the server: sudo docker restart kasm_agent sudo docker restart kasm_api sudo docker restart kasm_manager sudo docker restart kasm_db sudo docker restart kasm_proxy . IMPORTANT . You should be able to run all of this in an ec2 instance on AWS and then be able to run docker images stored on your instance through KASM. However, storage on EC2 instances is limited. If you are able to run docker images on an ec2 instance with KASM, that would be really impressive. . HACKS FOR KASM . In 3-4 sentences, please explain the significance of virtual desktops and KASM. How can virtual desktops such as these be utilized in our AP CSP environment? (0.45) . | Attempt to work through the KASM setup with your team. Attach two screenshots to show that you have successfully gone through the setup: The first screenshot of KASM generating your credentials, and the second screenshot of the KASM workspace once you have logged in. (0.45) . |",
            "url": "https://tri3devopteam.github.io/devops/2023/04/13/kasmec2.html",
            "relUrl": "/2023/04/13/kasmec2.html",
            "date": " • Apr 13, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "Title",
            "content": "acme.sh: acme.sh is a shell script that provides an alternative way to obtain and manage SSL/TLS certificates. It is a lightweight and versatile tool that can be used on a wide variety of web servers, including Apache, Nginx, and HAProxy. acme.sh uses the ACME protocol to communicate with Let&#39;s Encrypt and other certificate authorities, and supports a variety of verification methods, including DNS, HTTP, and TLS-SNI. Here&#39;s an example Python code that uses acme.sh to obtain a certificate for a domain: . import subprocess # set the domain name and web root directory domain = &quot;example.com&quot; webroot = &quot;/var/www/html&quot; # run the acme.sh command to obtain a certificate cmd = f&quot;acme.sh --issue --webroot {webroot} -d {domain}&quot; subprocess.run(cmd.split()) . ZeroSSL: ZeroSSL is a web-based certificate management tool that provides an alternative to Certbot. It allows you to obtain and manage SSL/TLS certificates through a web interface, without the need to install any software on your server. ZeroSSL supports both Let&#39;s Encrypt and Sectigo certificate authorities, and offers a variety of verification methods, including HTTP, DNS, and Email. Here&#39;s an example Python code that uses ZeroSSL to obtain a certificate for a domain: . import requests # set the domain name and email address domain = &quot;example.com&quot; email = &quot;user@example.com&quot; # make a request to ZeroSSL to obtain a certificate response = requests.post(&quot;https://zerossl.com/api/v2/certificates&quot;, json={ &quot;email&quot;: email, &quot;domains&quot;: [domain], &quot;certificate_validity_days&quot;: 90, &quot;validation_methods&quot;: [&quot;http&quot;, &quot;https&quot;, &quot;dns&quot;] }) # get the certificate data from the response certificate = response.json()[&quot;certificate&quot;] private_key = response.json()[&quot;key&quot;] . ego: lego is a command-line tool that provides an alternative to Certbot for managing SSL/TLS certificates. It supports a variety of web servers, including Apache, Nginx, and Caddy, and uses the ACME protocol to communicate with Let&#39;s Encrypt and other certificate authorities. lego offers a wide range of features, including support for wildcard certificates, DNS validation, and certificate bundling. Here&#39;s an example Python code that uses lego to obtain a certificate for a domain: .",
            "url": "https://tri3devopteam.github.io/devops/2023/04/03/Certbot.html",
            "relUrl": "/2023/04/03/Certbot.html",
            "date": " • Apr 3, 2023"
        }
        
    
  
    
        ,"post4": {
            "title": "AWS Databases",
            "content": "What are the different types of AWS Databases? . In order to meet the particular requirements of various use cases, AWS provides a variety of database services, each with its own special features and advantages. . Relational databases are among the most widely used AWS database types. Amazon Aurora, Amazon RDS, and Amazon Redshift are just a few of the relational databases that AWS offers. These databases are excellent for structured data and can be applied to financial applications, e-commerce platforms, and content management systems. . Non-relational databases, also known as NoSQL databases, are also provided by AWS. These databases can easily handle high data volumes and were made for unstructured data. Amazon DocumentDB and Amazon DynamoDB are two well-known NoSQL databases that AWS offers. . The graph database is another kind of database that AWS provides. Graph databases are made to store and manage highly connected data, like that found in social networks or recommendation systems. One example of a graph database provided by AWS is Amazon Neptune. . In-memory databases are available through AWS, they offer low-latency speed for applications that require quick data access. Amazon ElastiCache is an example of an in-memory database that can be used for apps like gaming. . In conclusion, the vast variety of databases available by AWS makes it easy for users to use the database that will best fit their work. .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2028/2023/03/28/redobigidea2-copy.html",
            "relUrl": "/markdown/week%2028/2023/03/28/redobigidea2-copy.html",
            "date": " • Mar 28, 2023"
        }
        
    
  
    
        ,"post5": {
            "title": "Duck DNS (Shaurya Goel)",
            "content": "How does Duck DNS Work? . Duck DNS is a free dynamic DNS service that allows users to assign a domain name to a dynamic IP address. Dynamic DNS (DDNS) is a system used to map a domain name to an IP address that may change frequently, such as the IP address assigned by an ISP to a residential or small business internet connection. . Once the client program is set up, it will periodically send an update to the Duck DNS servers with your current IP address. When someone tries to access your domain name, the DNS server will resolve the domain name to your current IP address, allowing the requester to connect to your device. . Overall, Duck DNS provides a convenient way to access your home network or devices from anywhere in the world, even if your ISP assigns you a dynamic IP address . How is Duck DNS useful for our project? Other Projects in General? . In general, Duck DNS can be useful for projects that involve remote access or control of a device, such as setting up a home security camera, remote desktop access, or hosting a website or game server from a home network. By using Duck DNS, the device or service can be accessed using a static hostname, which is more convenient than having to remember or constantly look up the device’s changing IP address. . In addition, Duck DNS is easy to set up and does not require any special hardware or software. It can be configured to update the IP address automatically, making it a reliable and low-maintenance solution for dynamic IP addresses. . Overall, Duck DNS is a useful tool for any project that requires a static hostname for remote access or control of a device or service. . Steps for Setup . Sign up for a DuckDNS account by visiting https://www.duckdns.org/ and selecting “Create Account.” | Once you have created an account, you will be prompted to create a subdomain. Enter a unique name for your subdomain, and then click the “Add Domain” button. | Next, you will need to download the DuckDNS client to keep your IP address updated. You can find the client at https://www.duckdns.org/install.jsp. Choose the appropriate client for your operating system. | Once you have downloaded the client, extract the files and run the installation script. | After installation, you will be prompted to enter your DuckDNS subdomain and token. You can find your token by logging into your DuckDNS account and clicking the “Install” tab. | Start the DuckDNS client, and it will automatically update your IP address every time it changes. You can confirm that the client is working by checking the “Logs” tab in your DuckDNS account. | Finally, you can use your DuckDNS subdomain to access your home network from the internet. To do this, you will need to configure your router to forward incoming requests to your local IP address. | . Video . Kahoot .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/03/27/DuckDNS.html",
            "relUrl": "/markdown/week%2020/2023/03/27/DuckDNS.html",
            "date": " • Mar 27, 2023"
        }
        
    
  
    
        ,"post6": {
            "title": "AWS Devolpment",
            "content": "by: Shivansh Goel . AWS Devolpment . Setting up the Server and Cloning the Project . Deployment Process: . First connect to an Ubuntu EC2 instance on AWS and then begin the system and software setup. | . Update and Upgrade the System . sudo apt update sudo apt upgrade | sudo apt install docker | sudo apt install docker-compose -y | sudo apt install html2text | sudo apt install python3-pip nginx | sudo pip3 install virtualenv | . Clone and Change Directory to project location . Clone your gitserver into a directory of your choosing . git clone https://github.com/yourgitserver | . Making sure that the Web Service can Run . To make sure that the Web Serbice to running properly . Run the main.py file and see if the server is able to run If there are some errors, try running the command: | pip install -r requirements.txt | . Make sure that there is a Dockerifle or that it is up to Date . Edit the Dockerfile: sudo nano Dockerfile Make sure that it looks like something like this: | . FROM docker.io/python:3.9 WORKDIR /app . — Update environment and install python and pip — . RUN apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get install -y python3 python3-pip git . — Copy repo you updated with clone or pull — . COPY . /app . — Install project specific dependencies — . RUN pip3 install –no-cache-dir -r requirements.txt RUN pip3 install gunicorn . — Setup args to run 3 workers and run on port 8080 — . ENV GUNICORN_CMD_ARGS=”–workers=3 –bind=0.0.0.0:8080” . — Allow port 8080 to be accessed by system — . EXPOSE 8080 . — Run Web Application in production style — . CMD [ “gunicorn”, “main:app” ] . Make sure that the docker-compose.yml is up to dagte . Edit the docker-compose.yml file and edit the flask_port, volumes, and the image | . Start Running Docker . sudo apt install docker | sudo apt install docker-compose -y | sudo docker-compose up -d | It should complete 9 steps of procesess to confirm that it is complete | . Make sure to Verify that the Web Application is working with Docker . docker-compose ps Make sure you find the application that matches the application name and ports. If you can’t find them that means that you did something wrong and that you should go back to finish other steps. | . Testing Localpoint . To make sure that all the previous steps are running correctly and the everything is going on the right path. You should run these commands to see if there is a success or a failure. . curl http://localhost:8086 If there is a “Failed to connect”, then that means that something is not going right and that you should look at the changes you have made in the server. | Another command to run would be: curl http://localhost:8086 | html2text | . | . Test preparation for Docker Web Application using IP for Internet Access . First make sure to install Nginx . Run the command to make sure that Nginx is installed within the system: sudo apt install nginx Move to /etc/nginx/sites-available whichis where the Nginx Server Configuration Files are located | Create your own configuration in the directory with a name of your choosing (sudo nano example) | Add these stuff to the Nginx Configuration File: server { listen 80; listen [::]:80; server_name 3.233.212.71; . location / { proxy_pass http://localhost:8086; # Simple requests if ($request_method ~* “(GET|POST)”) { add_header “Access-Control-Allow-Origin” *; } . # Preflight requests if ($request_method = OPTIONS ) { add_header &quot;Access-Control-Allow-Origin&quot; *; add_header &quot;Access-Control-Allow-Methods&quot; &quot;GET, POST, OPTIONS, HEAD&quot;; add_header &quot;Access-Control-Allow-Headers&quot; &quot;Authorization, Origin, X-Requested-With, Content-Type, Accept&quot;; return 200; } } } . | . Make sure to edit the server_name (IP Adress), the proxy pass POrt, and the docker-compose . Activate the NGINX Configuration . sudo ln -s /etc/nginx/sites-available/[your config file] /etc/nginx/sites-enabled[your config file] | sudo nginx -t If there are errors then you must go back and repeat the steps of the NGINX configuration in the sites-available directory and see if there is anything wrong or misplaced. | . Last Steps before the Last Steps . To Conclude the first part, make sure that the internet is now running your web application: Go on the internet and run this: http://(your ip address) | . The Last Steps . The last Steps involve setting up the DNS Server . Video . Are there any outdated Nginx/Docker functionalities to address? . As of right now there are no outdate Nginx/Docker functionalities that needed to be adressed, except to make sure to periodically run “sudo apt-get update”, and “‘sudo apt-get upgrade” | . Is there anything unclear that we need to communicate further to the students for deployment? . There is nothing unclear that needs to be communicated further except for the usage of the DuckDNS for the DNS Account and Server .",
            "url": "https://tri3devopteam.github.io/devops/markdown/week%2020/2023/03/27/AWSDevolpment.html",
            "relUrl": "/markdown/week%2020/2023/03/27/AWSDevolpment.html",
            "date": " • Mar 27, 2023"
        }
        
    
  
    
        ,"post7": {
            "title": "KASM Intro Guide",
            "content": "What is KASM? . In the words of the KASM co-director: . “KASM Workspaces delivers interactive access to GUI applications and desktop environments running in docker containers. The containers are streamed directly to the browser. The platform is similar to Citrix and VMware Horizon, but entirely container based.” . Essentially, KASM allows you to stream applications from docker containers. . Functionality Link: . KASM Functionalities . There are many different types of workspaces that KASM offers, such as: . Desktop Workspaces: Here, you can get desktop access in a moment of seconds from any device and from anywhere around the world. It is done in a secure manner through whichever web browser you like. | Functionality Demo: . Web Isolation Workspaces: There is a “zero-trust browser isolation” service. You can launch a private web browsing instance, where there is “no risk of compromising your endpoint.” | Functionality Demo: . Application Workspace (App Streaming): This is the main workspace which we are going to focus on. This workspace allows for an application container where the KASM platform does most of the heavylifting for us. It is customizable, open source, and kept up to date. You can choose either a server or cloud deployment option, and you can manage your own Self-Hosted Server in a separate version type created for this situation. | There are three different option plans for KASM: . Community Plan: Offers all enterprise features, and it is for personal use. You get community support, but there is a 5 concurrent session limit. . | Professional Plan: This is a $5 user/month plan. You get next business day support with this plan and a higher session limit. . | Their recommended plan, the Enterprise Plan: This is a $10 user/month plan, where you can get same business day support with all of the supported professional plan features. . | Why KASM? . It is incredibly scalable, and deployment automation can be done “for unique requirements and at massive scale” . | Easy to Access: You can log in from any web browser and whatever you are deploying can be hosted anywhere: private cloud, KASM hosted, etc. . | High Efficiency Levels: Uses Docker containers, reducing the resource requirements and creating fast session boots . | Very well-managed security: 2FA, LDAP, data loss prevention, security groups for privilege control of deployment, logging, and web filtering. . | Open-Source: All container tech available on Docker Hub and GitHub for people to view . |",
            "url": "https://tri3devopteam.github.io/devops/markdown/2023/03/26/kasm.html",
            "relUrl": "/markdown/2023/03/26/kasm.html",
            "date": " • Mar 26, 2023"
        }
        
    
  
    
        ,"post8": {
            "title": "Advanced Security Certbot",
            "content": "Certbot is a software run in Python. It is meant to convert HTTP sites to work with HTTPS, which is much more secure. Let’s first explore the background of HTTP to HTTPS: HTTPS and HTTP are almost essentially the same protocols, but HTTPS uses SSL to encrypt the requests and responses. Furthermore, HTTPS is also used in the form of SSL certificates used to encrypt and digitally sign these requests. HTTP runs on port 80, and is an incredibly insecure platform to run a site on. HTTPS runs on ports 80 and 443, and needs a Certification Authority signature for the SSL certificate being used on the https site. APPLICATION IN CSP, PROS/CONS During Trimester 1, while initially setting up our AWS deployment, we attempted to implement Let’s Encrypt, a certificate authority manager, along with Certbot. The Certbot configuration is relatively easy: as shown in Trimester 1, you have to install a couple of packages, create the certbot folders on the AWS deployment server, and activate HTTPS for your domain. Though it is relatively easy to use, we decided to weigh out some of the pros/cons of using Let’s Encrypt &amp; Certbot: PROS: . Let’s Encrypt is a free service. | It is issued very efficiently. | It is something that most of our students are already familiar with, so it is a smoother process to setup. CONS: | Certificates have to be replaced/renewed every 90 days. This can be a painful process, especially for multiple sites and groups to do. | Some domains block Let’s Encrypt, and have relationships with other SSL providers. | It is a platform that is vulnerable to malware attacks. Almost 15 thousand Let’s Encrypt certificates have been issued to phishing sites. Is this another risk that we want to factor in? In our opinion, this is too much to consider and it could be beneficial to look at alternatives. | To install and setup Certbot follow these instructions: . Install Certbot through the terminal with the following command sudo apt-get install certbot . | Next we have to choose a plugin to obtain and install the certificates. For Apache web servers, you can use the following command. If you are using a different browser engine, you can choose the corresponding plugin for that browser engine. sudo certbot –apache . | Next, you will need to follow the given prompts and certbot will help us set the rest up. You will need to enter your email address. . | Now you have to verify the installation and you can check if it’s working by checking the website in your browser, or using a tool such as SSL Labs, which can check for an SSL certificate. . | Now you have to ensure that your certbot will continue working with minimum maintenance. You can do this by making the certificate auto renew using this command. . | ””” sudo certbot renew “”” .",
            "url": "https://tri3devopteam.github.io/devops/markdown/2023/03/26/certbot.html",
            "relUrl": "/markdown/2023/03/26/certbot.html",
            "date": " • Mar 26, 2023"
        }
        
    
  

  
  
      ,"page0": {
          "title": "",
          "content": "Blogs .",
          "url": "https://tri3devopteam.github.io/devops/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tri3devopteam.github.io/devops/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}